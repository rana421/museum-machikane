{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# 恒等写像\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "# 入力層\n",
    "class Input:\n",
    "    # 入力結合重み行列Winの初期化\n",
    "    def __init__(self, N_u, N_x, input_scale, seed=0):\n",
    "        '''\n",
    "        param N_u: 入力次元\n",
    "        param N_x: リザバーのノード数\n",
    "        param input_scale: 入力スケーリング\n",
    "        '''\n",
    "        # 一様分布に従う乱数\n",
    "        np.random.seed(seed=seed)\n",
    "        self.Win = np.random.uniform(-input_scale, input_scale, (N_x, N_u))\n",
    "\n",
    "    # 入力結合重み行列Winによる重みづけ\n",
    "    def __call__(self, u):\n",
    "        '''\n",
    "        param u: N_u次元のベクトル\n",
    "        return: N_x次元のベクトル\n",
    "        '''\n",
    "        return np.dot(self.Win, u)\n",
    "\n",
    "\n",
    "# リザバー\n",
    "class Reservoir:\n",
    "    # リカレント結合重み行列Wの初期化\n",
    "    def __init__(self, N_x, density, rho, activation_func, leaking_rate,\n",
    "                 seed=0):\n",
    "        '''\n",
    "        param N_x: リザバーのノード数\n",
    "        param density: ネットワークの結合密度\n",
    "        param rho: リカレント結合重み行列のスペクトル半径\n",
    "        param activation_func: ノードの活性化関数\n",
    "        param leaking_rate: leaky integratorモデルのリーク率\n",
    "        param seed: 乱数の種\n",
    "        '''\n",
    "        self.seed = seed\n",
    "        self.W = self.make_connection(N_x, density, rho)\n",
    "        self.x = np.zeros(N_x)  # リザバー状態ベクトルの初期化\n",
    "        self.activation_func = activation_func\n",
    "        self.alpha = leaking_rate\n",
    "\n",
    "    # リカレント結合重み行列の生成\n",
    "    def make_connection(self, N_x, density, rho):\n",
    "        # Erdos-Renyiランダムグラフ\n",
    "        m = int(N_x*(N_x-1)*density/2)  # 総結合数\n",
    "        G = nx.gnm_random_graph(N_x, m, self.seed)\n",
    "\n",
    "        # 行列への変換(結合構造のみ）\n",
    "        #connection = nx.to_numpy_matrix(G)\n",
    "        connection = nx.to_numpy_array(G) #上のやつだとどうにもエラーが出るので修正\n",
    "        W = np.array(connection)\n",
    "\n",
    "        # 非ゼロ要素を一様分布に従う乱数として生成\n",
    "        rec_scale = 1.0\n",
    "        np.random.seed(seed=self.seed)\n",
    "        W *= np.random.uniform(-rec_scale, rec_scale, (N_x, N_x))\n",
    "\n",
    "        # スペクトル半径の計算\n",
    "        eigv_list = np.linalg.eig(W)[0]\n",
    "        sp_radius = np.max(np.abs(eigv_list))\n",
    "\n",
    "        # 指定のスペクトル半径rhoに合わせてスケーリング\n",
    "        W *= rho / sp_radius\n",
    "\n",
    "        return W\n",
    "\n",
    "    # リザバー状態ベクトルの更新\n",
    "    def __call__(self, x_in):\n",
    "        '''\n",
    "        param x_in: 更新前の状態ベクトル\n",
    "        return: 更新後の状態ベクトル\n",
    "        '''\n",
    "        #self.x = self.x.reshape(-1, 1)\n",
    "        self.x = (1.0 - self.alpha) * self.x \\\n",
    "                 + self.alpha * self.activation_func(np.dot(self.W, self.x) \\\n",
    "                 + x_in)\n",
    "        return self.x\n",
    "\n",
    "    # リザバー状態ベクトルの初期化\n",
    "    def reset_reservoir_state(self):\n",
    "        self.x *= 0.0\n",
    "\n",
    "\n",
    "# 出力層\n",
    "class Output:\n",
    "    # 出力結合重み行列の初期化\n",
    "    def __init__(self, N_x, N_y, seed=0):\n",
    "        '''\n",
    "        param N_x: リザバーのノード数\n",
    "        param N_y: 出力次元\n",
    "        param seed: 乱数の種\n",
    "        '''\n",
    "        # 正規分布に従う乱数\n",
    "        np.random.seed(seed=seed)\n",
    "        self.Wout = np.random.normal(size=(N_y, N_x))\n",
    "\n",
    "    # 出力結合重み行列による重みづけ\n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        param x: N_x次元のベクトル\n",
    "        return: N_y次元のベクトル\n",
    "        '''\n",
    "        return np.dot(self.Wout, x)\n",
    "\n",
    "    # 学習済みの出力結合重み行列を設定\n",
    "    def setweight(self, Wout_opt):\n",
    "        self.Wout = Wout_opt\n",
    "\n",
    "\n",
    "# 出力フィードバック\n",
    "class Feedback:\n",
    "    # フィードバック結合重み行列の初期化\n",
    "    def __init__(self, N_y, N_x, fb_scale, seed=0):\n",
    "        '''\n",
    "        param N_y: 出力次元\n",
    "        param N_x: リザバーのノード数\n",
    "        param fb_scale: フィードバックスケーリング\n",
    "        param seed: 乱数の種\n",
    "        '''\n",
    "        # 一様分布に従う乱数\n",
    "        np.random.seed(seed=seed)\n",
    "        self.Wfb = np.random.uniform(-fb_scale, fb_scale, (N_x, N_y))\n",
    "\n",
    "    # フィードバック結合重み行列による重みづけ\n",
    "    def __call__(self, y):\n",
    "        '''\n",
    "        param y: N_y次元のベクトル\n",
    "        return: N_x次元のベクトル\n",
    "        '''\n",
    "        return np.dot(self.Wfb, y)\n",
    "\n",
    "\n",
    "# Moore-Penrose擬似逆行列\n",
    "class Pseudoinv:\n",
    "    def __init__(self, N_x, N_y):\n",
    "        '''\n",
    "        param N_x: リザバーのノード数\n",
    "        param N_y: 出力次元\n",
    "        '''\n",
    "        self.X = np.empty((N_x, 0))\n",
    "        self.D = np.empty((N_y, 0))\n",
    "        \n",
    "    # 状態集積行列および教師集積行列の更新\n",
    "    def __call__(self, d, x):\n",
    "        x = np.reshape(x, (-1, 1))\n",
    "        d = np.reshape(d, (-1, 1))\n",
    "        self.X = np.hstack((self.X, x))\n",
    "        self.D = np.hstack((self.D, d))\n",
    "        \n",
    "    # Woutの最適解（近似解）の導出\n",
    "    def get_Wout_opt(self):\n",
    "        Wout_opt = np.dot(self.D, np.linalg.pinv(self.X))\n",
    "        return Wout_opt\n",
    "\n",
    "\n",
    "# リッジ回帰（beta=0のときは線形回帰）\n",
    "class Tikhonov:\n",
    "    def __init__(self, N_x, N_y, beta):\n",
    "        '''\n",
    "        param N_x: リザバーのノード数\n",
    "        param N_y: 出力次元\n",
    "        param beta: 正則化パラメータ\n",
    "        '''\n",
    "        self.beta = beta\n",
    "        self.X_XT = np.zeros((N_x, N_x))\n",
    "        self.D_XT = np.zeros((N_y, N_x))\n",
    "        self.N_x = N_x\n",
    "\n",
    "    # 学習用の行列の更新\n",
    "    def __call__(self, d, x):\n",
    "        x = np.reshape(x, (-1, 1))\n",
    "        d = np.reshape(d, (-1, 1))\n",
    "        self.X_XT += np.dot(x, x.T)\n",
    "        self.D_XT += np.dot(d, x.T)\n",
    "\n",
    "    # Woutの最適解（近似解）の導出\n",
    "    def get_Wout_opt(self):\n",
    "        X_pseudo_inv = np.linalg.inv(self.X_XT \\\n",
    "                                     + self.beta*np.identity(self.N_x))\n",
    "        Wout_opt = np.dot(self.D_XT, X_pseudo_inv)\n",
    "        return Wout_opt\n",
    "\n",
    "\n",
    "# 逐次最小二乗（RLS）法\n",
    "class RLS:\n",
    "    def __init__(self, N_x, N_y, delta, lam, update):\n",
    "        '''\n",
    "        param N_x: リザバーのノード数\n",
    "        param N_y: 出力次元\n",
    "        param delta: 行列Pの初期条件の係数（P=delta*I, 0<delta<<1）\n",
    "        param lam: 忘却係数 (0<lam<1, 1に近い値)\n",
    "        param update: 各時刻での更新繰り返し回数\n",
    "        '''\n",
    "        self.delta = delta\n",
    "        self.lam = lam\n",
    "        self.update = update\n",
    "        self.P = (1.0/self.delta)*np.eye(N_x, N_x) \n",
    "        self.Wout = np.zeros([N_y, N_x])\n",
    "        \n",
    "    # Woutの更新\n",
    "    def __call__(self, d, x):\n",
    "        x = np.reshape(x, (-1, 1))\n",
    "        for i in np.arange(self.update):\n",
    "            v = d - np.dot(self.Wout, x)\n",
    "            gain = (1/self.lam*np.dot(self.P, x))\n",
    "            gain = gain/(1+1/self.lam*np.dot(np.dot(x.T, self.P), x))\n",
    "            self.P = 1/self.lam*(self.P-np.dot(np.dot(gain, x.T), self.P))\n",
    "            self.Wout += np.dot(v, gain.T)\n",
    "\n",
    "        return self.Wout\n",
    "\n",
    "\n",
    "# エコーステートネットワーク\n",
    "class ESN:\n",
    "    # 各層の初期化\n",
    "    def __init__(self, N_u, N_y, N_x, density=0.05, input_scale=1.0,\n",
    "                 rho=0.95, activation_func=np.tanh, fb_scale = None,\n",
    "                 fb_seed=0, noise_level = None, leaking_rate=1.0,\n",
    "                 output_func=identity, inv_output_func=identity,\n",
    "                 classification = False, average_window = None):\n",
    "        '''\n",
    "        param N_u: 入力次元\n",
    "        param N_y: 出力次元\n",
    "        param N_x: リザバーのノード数\n",
    "        param density: リザバーのネットワーク結合密度\n",
    "        param input_scale: 入力スケーリング\n",
    "        param rho: リカレント結合重み行列のスペクトル半径\n",
    "        param activation_func: リザバーノードの活性化関数\n",
    "        param fb_scale: フィードバックスケーリング（default: None）\n",
    "        param fb_seed: フィードバック結合重み行列生成に使う乱数の種\n",
    "        param leaking_rate: leaky integratorモデルのリーク率\n",
    "        param output_func: 出力層の非線形関数（default: 恒等写像）\n",
    "        param inv_output_func: output_funcの逆関数\n",
    "        param classification: 分類問題の場合はTrue（default: False）\n",
    "        param average_window: 分類問題で出力平均する窓幅（default: None）\n",
    "        '''\n",
    "        self.Input = Input(N_u, N_x, input_scale)\n",
    "        self.Reservoir = Reservoir(N_x, density, rho, activation_func, \n",
    "                                   leaking_rate)\n",
    "        self.Output = Output(N_x, N_y)\n",
    "        self.N_u = N_u\n",
    "        self.N_y = N_y\n",
    "        self.N_x = N_x\n",
    "        self.y_prev = np.zeros(N_y)\n",
    "        self.output_func = output_func\n",
    "        self.inv_output_func = inv_output_func\n",
    "        self.classification = classification\n",
    "\n",
    "        # 出力層からのリザバーへのフィードバックの有無\n",
    "        if fb_scale is None:\n",
    "            self.Feedback = None\n",
    "        else:\n",
    "            self.Feedback = Feedback(N_y, N_x, fb_scale, fb_seed)\n",
    "\n",
    "        # リザバーの状態更新おけるノイズの有無\n",
    "        if noise_level is None:\n",
    "            self.noise = None\n",
    "        else:\n",
    "            np.random.seed(seed=0)\n",
    "            self.noise = np.random.uniform(-noise_level, noise_level, \n",
    "                                           (self.N_x, 1))\n",
    "\n",
    "        # 分類問題か否か\n",
    "        if classification:\n",
    "            if average_window is None:\n",
    "                raise ValueError('Window for time average is not given!')\n",
    "            else:\n",
    "                self.window = np.zeros((average_window, N_x))\n",
    "\n",
    "    # バッチ学習\n",
    "    def train(self, U, D, optimizer, trans_len = None):\n",
    "        '''\n",
    "        U: 教師データの入力, データ長×N_u\n",
    "        D: 教師データの出力, データ長×N_y\n",
    "        optimizer: 学習器\n",
    "        trans_len: 過渡期の長さ\n",
    "        return: 学習前のモデル出力, データ長×N_y\n",
    "        '''\n",
    "        train_len = len(U)\n",
    "        if trans_len is None:\n",
    "            trans_len = 0\n",
    "        Y = []\n",
    "\n",
    "        # 時間発展\n",
    "        for n in range(train_len):\n",
    "            x_in = self.Input(U[n])\n",
    "\n",
    "            # フィードバック結合\n",
    "            if self.Feedback is not None:\n",
    "                x_back = self.Feedback(self.y_prev)\n",
    "                x_in += x_back\n",
    "\n",
    "            # ノイズ\n",
    "            if self.noise is not None:\n",
    "                x_in += self.noise\n",
    "\n",
    "            # リザバー状態ベクトル\n",
    "            x = self.Reservoir(x_in)\n",
    "\n",
    "            # 分類問題の場合は窓幅分の平均を取得\n",
    "            if self.classification:\n",
    "                self.window = np.append(self.window, x.reshape(1, -1),\n",
    "                                        axis=0)\n",
    "                self.window = np.delete(self.window, 0, 0)\n",
    "                x = np.average(self.window, axis=0)\n",
    "\n",
    "            # 目標値\n",
    "            d = D[n]\n",
    "            d = self.inv_output_func(d)\n",
    "\n",
    "            # 学習器\n",
    "            if n > trans_len:  # 過渡期を過ぎたら\n",
    "                optimizer(d, x)\n",
    "\n",
    "            # 学習前のモデル出力\n",
    "            y = self.Output(x)\n",
    "            Y.append(self.output_func(y))\n",
    "            self.y_prev = d\n",
    "\n",
    "        # 学習済みの出力結合重み行列を設定\n",
    "        self.Output.setweight(optimizer.get_Wout_opt())\n",
    "\n",
    "        # モデル出力（学習前）\n",
    "        return np.array(Y)\n",
    "\n",
    "    # バッチ学習後の予測\n",
    "    def predict(self, U):\n",
    "        test_len = len(U)\n",
    "        Y_pred = []\n",
    "\n",
    "        # 時間発展\n",
    "        for n in range(test_len):\n",
    "            x_in = self.Input(U[n])\n",
    "\n",
    "            # フィードバック結合\n",
    "            if self.Feedback is not None:\n",
    "                x_back = self.Feedback(self.y_prev)\n",
    "                x_in += x_back\n",
    "\n",
    "            # リザバー状態ベクトル\n",
    "            x = self.Reservoir(x_in)\n",
    "\n",
    "            # 分類問題の場合は窓幅分の平均を取得\n",
    "            if self.classification:\n",
    "                self.window = np.append(self.window, x.reshape(1, -1),\n",
    "                                        axis=0)\n",
    "                self.window = np.delete(self.window, 0, 0)\n",
    "                x = np.average(self.window, axis=0)\n",
    "\n",
    "            # 学習後のモデル出力\n",
    "            y_pred = self.Output(x)\n",
    "            Y_pred.append(self.output_func(y_pred))\n",
    "            self.y_prev = y_pred\n",
    "\n",
    "        # モデル出力（学習後）\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    # バッチ学習後の予測（自律系のフリーラン）\n",
    "    def run(self, U):\n",
    "        test_len = len(U)\n",
    "        Y_pred = []\n",
    "        y = U[0]\n",
    "\n",
    "        # 時間発展\n",
    "        for n in range(test_len):\n",
    "            x_in = self.Input(y)\n",
    "\n",
    "            # フィードバック結合\n",
    "            if self.Feedback is not None:\n",
    "                x_back = self.Feedback(self.y_prev)\n",
    "                x_in += x_back\n",
    "\n",
    "            # リザバー状態ベクトル\n",
    "            x = self.Reservoir(x_in)\n",
    "\n",
    "            # 学習後のモデル出力\n",
    "            y_pred = self.Output(x)\n",
    "            Y_pred.append(self.output_func(y_pred))\n",
    "            y = y_pred\n",
    "            self.y_prev = y\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    # オンライン学習と予測\n",
    "    def adapt(self, U, D, optimizer):\n",
    "        data_len = len(U)\n",
    "        Y_pred = []\n",
    "        Wout_abs_mean = []\n",
    "\n",
    "        # 出力結合重み更新\n",
    "        for n in np.arange(0, data_len, 1):\n",
    "            x_in = self.Input(U[n])\n",
    "            x = self.Reservoir(x_in)\n",
    "            d = D[n]\n",
    "            d = self.inv_output_func(d)\n",
    "            \n",
    "            # 学習\n",
    "            Wout = optimizer(d, x)\n",
    "\n",
    "            # モデル出力\n",
    "            y = np.dot(Wout, x)\n",
    "            Y_pred.append(y)\n",
    "            Wout_abs_mean.append(np.mean(np.abs(Wout)))\n",
    "\n",
    "        return np.array(Y_pred), np.array(Wout_abs_mean)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
